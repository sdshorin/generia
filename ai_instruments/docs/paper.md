
(внутренние комментарии. Зачем ты смотришь файлы в истории гита?)



Добавить во введение - предпосылки работы. так как согласно последним аналитическим оборам (template_literature_link) рынок труда в IT сфере потерпит катастрофические изменения: работу, которую сейчас выполняют junior и middle специалисты, через несколько лет начнут выполнять ИИ под руководством senior специалистов. 



- LangChain, LangGraph - это аналоги Chain-of-Thought (CoT), добавить в диплом


Добавить про микросервисы:
- требуется чтобы они были stateless


особенности написания с ИИ
- постоянно улучшаются инструменты (claude code, Claude 4, ChatGPT o3)
- Но некоторые инструементы исчезают - Galileo был выкуплен гуглом и переведен на Gemini 2.5, из-за чего большинство инструментов отключилось, и продуктом стало невозможно пользоваться (так как отключили подписки, а новый продукт на основе Gemini был опубликован только как прототип - и генерировал дизайн куда хуже - не использовал фигму, не подбирал дизайн, и в целом в плане дизайна создавал сайты на уровне обычных моделей, а не специализированных инструментов для UI/UX типа Galileo )


программист выступает в роли критика
Декларативный стиль программирование - программист детально описывает ситему\программу и как она должна выглядеть, но написание самой программы делегирует агенту. 


Задачи и цели
- Проверить, развились ли системы генерации кода с ИИ до той степени, что с их помощью можно писать большие и серьезные проекты. И если да - понять, как будет выглядеть процесс разработки в будущем, и выработать методики работы с кодом для такой разработки.
- Проверить гипотезу, что в будущем вместо целой команды разработчиков над проектом будет работать только один человек с множеством ИИ ассистентов (ссылки на статьи что многие стартапы уже работают по такий методике)

Вывод
- возможно
- требуется хорошие "горизонтальные знания" - фронтенд, бэкенд, безопасность, и тд, Computer  science, фундаментальное образование (автор предсказывал это еще 4 года назад, когда ушел с full time работы программистом на бакалвариат)
- Требуется понимания каждой строчки, написанной ИИ (в этом проекте это соблюдается только частично - автор понимает работу фронтенда только в общих чертах)
- Если задача описана без деталей - то ИИ додумывает ее, и часто - не в ту сторону, что планировалось. Если задача описана хорошо - все равно совершает ошибки, поэтому код нужно всегда перепроверять - иначе придется потом искать баг в совершенно незнакомом коде, что занимает много времени (хотя баг был виден на этапе генерации) - (например - код в генераторе мира был с ошибкой в логике - одна из задач предполагала, что некоторые посты могут быть без картинки. Из-за чего возникал непонятный баг, причину которого пришлось долго искать)


Как выбирать модели - SWE Branch

(Какая бывает разработка кода с ИИ - копирование кода через веб интерфпейс модели и работа с файлами(а если ограничение на количество файлов - объединение кода в один документ), или Использование специальных агентов, устройство агентов описано в статье .... )

(нужен специальный раздел, где описана архитектура агентов для написания кода!! нужно пересказать статью - https://arxiv.org/abs/2405.15793 SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering. Примерно на 2-3 страницы, основные тезисы)

Агенты
claude code - мощно, но дорого (cil)
augment - тоже дорого (если по подписке), но так же имеет собственный движок поиска. Работает более мелкими шагами . работает дольше, следить за процессом генерации кода и проверять его - не так удобно. (форк VScode)
- не переписывает целые файлы за раз как claude code, а работает с маленькими изменениями по несколько строчек
cursor- использует более простые модели, поэтому дешевле, но теряется в больших проектах. (плагин VS Code)



Основные проблемы:
1. детальные промпты (md файлы)
2. ограничение контекста модели на больших проектах - нужно директивно в тз указывать, какие файлы нужно изменить, иначе ИИ агент начинает теряться в коде и забивать контекст (что ухудшает работу модели и увеличивает стоимость)
3. ограниченные знания модели - решается моделями, которые умеют гуглить (chatgpt o3 хорошо справляется с такими вопросами)


чтобы работать с большими проектами и хорошо ориентироваться в коде
- либо использовать встроенные в агента поисковые движки (Agument)
- Либо указывать директивно пути к файлам в промпте
- Либо автоматически генерировать с помощью моделей с большим контекстом README файлы с документацией, которые указывать в промпте

Правила:
- большие детальные промпты на каждый шаг (некотрые примеры промптов - в репозатории)
- всегда - ручная перепроверка кода (с помощью diff - либо в git, либо во встроенном инструменте в самом агенте)
- файлы не должны разрастаться (оптимально - не более 400-500 срок)
- В промпте нужно рассказывать про проект и про то, как он работает - чтобы модель не забивала контекст кодом и не тратила время на разбирательства, а сразу начинала работать над задачей



Как выглядит разработка:
- долго пишу промпт и продумываю идею и архитектуру - обсуждая ее с claude и chatgpt в веб-версиях.
- когда в голове складывается решение - пишу большой и подробный md файл с описанием задачи (сслыка на пример файла), а так же пишу сам промпт в отдельном файле или в заметках
- затем копирую эот промпт в агента
- Слежу за процессом генерации и читаю код сразу, как модель его написала. Если генерация пошла не туда - останавливаю ее, и переписываю промпт. (Код перестает быть ценностью, поэтому в процессе работы часто приходится удалять сотни строчек сгенерированного кода и перезапускать задачу - если в коде были архитектурные проблемы). Фокус работы смещается на написание документации
- Компилирую и тестирую код, сообщения о любых ошибках отправляю в тот эе диалог с агентом, в котором уже прогружен весь контекст работы.

Использование русского языка в промпте - хуже, но не так сильно чтобы снижать удобство разработки (нужно найти статьи)

Часто приходится отменять изменения модели. И для этого в Cursor и Agument есть специальные инструменты


 Добавить в диплом:


1. Почему аи генерация - ссылки на рост способностей ИИ, и если этих способностей недостаточно - то на рост вычислительной мощности
2. Chiper.ai - добавить, что есть хороший пример фронтенда и пример просмотра промптов и пример интерфейса
3. Статьи из https://chirper.fun https://chirper.fun/whitepaper.pdf


 Почему выбран именно такой проект.
 Хочелось отчетить на вопрос: может ли один разработчик сделать проект уровня, когда не стыдно выпускать на прод - и сделать это быстро и в одиночку. Чтобы не фокусироваться на бизнес-аспектах, был выбран тривиальный проект - Generia ,который хоть и обладает всем функционалом, по факту не является серьезным быстрым продуктом.
 Основное требование было - сделать рабочий MVP, который будет отвечать современынм требованиям и высокой нагрузке - поэтому в выборе технологий и архитектуры не было задачи "выбрать идеальные технологии и сделать идельную архитектуру". Наоборот, требовалась архитектура, котору можно далдьше развивать и работать над ней (то есть одно из главных требоываний - чтобы проект не потребовалось потом переписывать с нуля), и реализовывался необходимый минимум для MVP - который отвечал требованиеям поддерживаемости (так как для ИИ-сгенерированного кода это основная трудность), надежности (так как ИИ-код часто наполнне различными уязвиостями ) и высоконагруженности (так как проект должен выдерживать любые нагрузки - иначе в какой-то момент его придется полностью переписать, что не имеет смысла)

Проблема работы с ИИ не в том, чтобы написать работающий код. А в том ,чтобы написать поддерживаемый код, с которым можно будет работать в дальнейшем.


Переход от kafka к Temporal Workflow Engine

Основная проблема - перезапуск упавших задач и требование выполнения exatcly-one (так как вызовы api дорогие)



невозможно генерировать код в проект, который ты не смог бы написать сам - потому что тогда 100% будет упущена важная деталь и проект не будет работать 

Пример работы с ИИ:


Рефакторинг ai-worker - самый яркий пример.
8500 строк на python, из них нужно изменить примерно 3-4 тысячи - чтобы перевести очередь задач с kafka на Temporal Workflows, а так же сделать обновление статуса генерации через Signal.

примерно 2 часа заняло исследование возможностей Temporal Workflows.
Затем было предпринято 3 попытки написать код - каждый раз с помощью Claude Code генерировалось примерно 2-3 тысячи строк кода, которые были не ролевантны - и после каждой попытки промпт уточнялся и дописывался. каждое предложение в промпте должно быть однозначно и конкретно

с 3 попытки получилось написать код - промпт в этот момент разросся до 70 строк (можно посмотреть в репозатории)

В итоге были затрачены ресурсы:

```
Total cost:            $8.20
Total duration (API):  34m 47.1s
Total duration (wall): 1h 0m 58.9s
Total code changes:    4596 lines added, 365 lines removed
Token usage by model:
    claude-3-5-haiku:  67.7k input, 1.4k output, 0 cache read, 0 cache write
       claude-sonnet:  625 input, 104.5k output, 14.9m cache read, 556.7k cache write

```
и получен частично работающий код - в котором была только часть функционала, но код был с подходящей мне структурой.

Далее я прочитал код, запустил - и увидел проблемы с распределением ресурсов (коннектов к бд) между воркерами.


Я написал несколько исследовательских запросов к chatgpt и perplexity (с формулировкой проекта и проблемы, и просьбой найти в интернете решение)(имеется ввиду аналог Deep research от Perplexity и модель o3 с доступом к интернету - оба иснтрумента составили отчеты, основываясь прмерно на 10-20 источниках из интернета), и сложил их и их результаты в один файл, который прикрепил к запросу. И написал промпт примерно на 10 строк с описанием проблемы и ссылкой на файл - и отправил промпт в claude code. 
В результате структура кода улучшилась и работа с Temporal стала соответствовать best practices.

после выполнения задания я задал промпт "улучшить README ai-worker" - чтобы в будущем другие агнеты хорошо ориентировались по коду.
(REadme занимает примерно 400 строк )

Итого на финальные правки:
Total cost:            $2.69
Total duration (API):  13m 15.4s
Total duration (wall): 35m 52.7s
Total code changes:    1316 lines added, 1106 lines removed
Token usage by model:
    claude-3-5-haiku:  50.4k input, 1.1k output, 0 cache read, 0 cache write
       claude-sonnet:  8.4k input, 33.9k output, 3.8m cache read, 258.3k cache write


В дальнейшем еще потребовалась отладка кода, но все следующие запросы строились по такому же сценарию и работали с куда меньшим контекстом.

В результате получилось запустить процесс генерации, но возникли осложнения, с которыми ИИ - агент не смог справиться (и это позволило найти его лимиты возможностей - сделать на этом акцент и упомянуть в других частях). А именно - возникли проблемы внутри temporal из-за side effects в BaseModel (Python).

То есть(про границы возможностей ИИ):
1. Агент успешно справился с написанием обычного ai-worker на Python и kafka - и сразу исправлял проблемы в коде, стоило ему на них указать и уточнить, как именно исправить (при этом агент для каждой задачи читал несколько тысяч строк кода и успешно ориентировался в нем)
2. Аге






Выводы:

- да, ИИ агенты могут помочь в работе надо большими проектами. Их главное ограничение на текущий момент - это размер контекста (за раз агент может обрабатывать до 2000-4000 строк контекста. Но когда контекст становится длинее 6 тысяч - агент начинает теряться. И чем с большим количеством кода агнет работает - тем более точные и большие промпты требует




проверка работы агентов при ограниченном объеме контекста:
0. Фронт был сверстан с помощью шаблона и Claude 4
переписывание фронта с Claude Code. Проблема в том, что каждая страница - это 500 строк html со стилями и сложной версткой(и длинными строчками - поэтому контекст забивается куда быстрее), поэтому 
агент теряется при работе, если просить его за один проход выделить все стили из страницы и переписать фронтенд сайта - контекстное окно (у Claude 4 Sonnet + claude code) кончается в момент, когда агент только переходит от работы с отдельными элементами к верстке самой странице.

Поэтому работа с новым фронтом шла поэтапно.
0. Генерация по шаблону
1. Были выделены общие стили и элементы из шаблонов
2. Шаблоны были переписаны с использованием новых стилей и шиблонов (добавить ссылку на промпты?)
4. и затем уже подготовленные шаблоны были использованы для изменения основного фронтенда.
При этом на каждом этапе генерировалось множество md файлов, которые помогали сохранять метаданные проекта и инструкции для моделей.

пример промпта для генерации плана
```prompt

У меня есть проект - (./README.md) - генерация виртуальных миров.
Я хочу полностью переделать фронтенд - frontend/README.md

Для этого я создал новые шаблоны страниц, и разбил их на компоненты и стили - ai_instruments/front_3_prepared/*, ai_instruments/front_3_prepared/DEVELOPMENT_GUIDE.md.

Помоги мне полностью переписать фронтенд в проекте.

Продумай и составь план перехода, запиши его в отдельный md файл. Этот файл должен содержать максимально подробные инструкции для LLM агента, который будет осуществлять переход. Я буду каждый раз отправлять этот план в LLM агента, и агент будет выполнять несколько пунктов из этого плана, и затем обновлять сам план.
```


пример промпта. Причем каждый md файл тут - это сгенерированный документ на 300-600 строк
```prompt
У меня есть проект - (./README.md) - генерация виртуальных миров.
Я хочу полностью переделать фронтенд - frontend/README.md
Для этого я создал новые шаблоны страниц, и разбил их на компоненты и стили - ai_instruments/front_3_prepared/*, ai_instruments/front_3_prepared/DEVELOPMENT_GUIDE.md.
Я создал план миграции - FRONTEND_MIGRATION_PLAN.md. Выполняй задачи по этому плану, перепиши фронтенд, (не забывай обновлять FRONTEND_MIGRATION_PLAN.md ) (Ты можешь копировать файлы - bash:cp)
ultrathink
```
(ultrathink - ключевое слово для claude code, которое позволяет включить режим мышления)











Особенности написания промптов для модели:
они должны быть детальны и однозначны.
А чем больше кода нужно сгенерировать - тем больше нужен промпт, чтобы он оставался однозначным.
если промпт не однозначный - агент может упрощать код.

(хочется добавить, что в коде промпта даже оттенки слов важны, и с их помощью можно управлять генерацией кода - например, балансировать дествия агента - и тем самым тонко настраивать его код. но тут не понятно сформулировал. Нужно на  примере - типа, (найти - что-то про глубину рефакторирнга))
(то есть при написанни промпта нужно как бы смотреть на него со стороны и понимать, как смысл слов в промте восприймет модель или сторонние люди. может быть, при прочтении они считают из него соверщенно другой смысл?)







Анализ ИИ кода (на примере генерации мира )

- местами код нужно реорганизовать (вынести в отдельные функции, это улучшило бы архитектуру)

- но код пишется на высоком уровне и с комментариями


при запуске большого промпта - нужно запустить агента (claude code) с think и подождать, когда он начнет редактировать первый файл. И проверить, по каким файлам он ходил и что планировал - только когда убедишься, что агент верно тебя понял, его можно запускать работать далее (относится только к сложным промптам)




Фронтенд проекта - так как автор не обладает экспертизой во фронтенде, фронтенд проекта довольно простой, чтобы он мог целиком уместиться в контексте модели (и тем самым облегчить разработку)




Способность агента искать баги: 
- модель хорошо справляется с багами, в которых предоставлены stack-trace и детали (если stacke-trace из одного микросервиса - нужно добавить агенту ссылки на код, связанный с багом, в другом микросервисе.)
- самостоятельный поиск багов лишь по краткому описанию проекта - срабатывает только с маленькими проектами. С большими проектами - модель начинает галлюционировать, поэтмоу в промте-описании бага модели нужно добавить возможные гипотезы возникновения проблемы - просто описания "что не так" может быть не достатояно для агента



агент пытается галлюцинировать и не так прочитать промпты - задача разработчика - всегда держать его в ежовых рукавицах и под строгим контролем.



Нагрузочное тестирование!!!!!!!!!!!! - как проверка, что проект получился production ready


в результате работы была разработана методология работы с LLM агентами

(тут нужно сделать выводы по всему файлу выше. про то как нужно работать с промптами, контекстом, использовать md файлы, использовать системы поиска на основе LLM и добавлять их результаты в проект ,чтобы агент смог ими воспользоваться, перепроверять код, перегенерировать код если что то не нравится, и тд)

(вывод - люди, которые не умеют писать код, могут с новыми агентами сделать ограниченные проекты. Но разработчики с опытом могут делать гораздо более сложные и надежные проекты)







