# Техническое задание на разработку микросервиса AI Worker для платформы Generia

## 1. Общее описание

Generia — это платформа для создания и исследования виртуальных миров с контентом, генерируемым искусственным интеллектом. Проект представляет собой микросервисную архитектуру, моделирующую изолированные социальные сети.

Требуется разработать микросервис **AI Worker**, отвечающий за генерацию всего контента в виртуальных мирах: описания миров, пользователей, постов и медиа-контента. Микросервис должен обеспечивать асинхронную обработку задач, возможность отслеживания прогресса генерации и обработку ошибок при взаимодействии с внешними API.

## 2. Архитектура микросервиса

### 2.1. Технологический стек
- **Язык программирования**: Python 3.10+ с asyncio
- **Очередь сообщений**: Apache Kafka
- **База данных**: MongoDB
- **Внешние API**: 
  - Google Gemini 2.5 Flash (LLM для текстового контента)
  - API для генерации изображений (TBD)
- **Контейнеризация**: Docker и Docker Compose

### 2.2. Компоненты микросервиса
- **Обработчик Kafka**: асинхронный потребитель сообщений
- **Система задач**: классы Task и BaseJob с наследниками для конкретных задач
- **Клиенты для внешних API**: обертки для работы с LLM и генераторами изображений
- **Менеджер прогресса**: компонент для отслеживания и обновления статуса генерации

## 3. Модель данных и потоки задач

### 3.1. Основные сущности

**Task** - хранит в MongoDB следующую информацию:
- `_id`: UUID задачи
- `type`: тип задачи (например, "generate_world_description")
- `world_id`: UUID мира
- `status`: статус задачи ("pending", "in_progress", "completed", "failed")
- `worker_id`: ID воркера, обрабатывающего задачу (для идемпотентности)
- `parameters`: словарь с параметрами, специфичными для конкретного типа задачи
- `result`: результат выполнения задачи
- `created_at`: время создания задачи
- `updated_at`: время последнего обновления
- `attempt_count`: количество попыток выполнения
- `error`: описание ошибки (если есть)

**WorldGenerationStatus** - хранит в MongoDB информацию о процессе генерации мира:
- `_id`: UUID мира
- `status`: общий статус генерации ("pending", "in_progress", "completed", "failed")
- `current_stage`: текущий этап генерации
- `stages`: список этапов с информацией о прогрессе
- `tasks_total`: общее количество задач, которые нужно выполнить
- `tasks_completed`: количество выполненных задач
- `tasks_failed`: количество неудачных задач
- `task_predicted`: примерное количество задач всего (вычислено примерно - для отображения пользователю)
- `users_created`
- `posts_created`
- `users_predicted`
- `posts_predicted`
- `api_call_limits_LLM`: лимиты на количество вызовов API (LLM, изображения)
- `api_call_limits_images`: лимиты на количество вызовов API (LLM, изображения)
- `api_calls_made_LLM`: текущее количество сделанных вызовов API
- `api_calls_made_images`: текущее количество сделанных вызовов API
- `parameters`: параметры генерации (количество пользователей, постов и т.д.)
- `created_at`: время начала генерации
- `updated_at`: время последнего обновления

**WorldParameters** - хранит в MongoDB описание мира. Это описание сохраняет generate_world_description, и дальше все остальные задачи загружают это описание мира для дальнейшей обработки

### 3.2. Процесс обработки задачи

1. Воркер получает ID задачи из Kafka.
2. Загружает данные задачи из MongoDB.
3. Проверяет, не выполняется ли задача другим воркером (идемпотентность).
4. Через фабрику создает соответствующий Job-объект.
5. Job выполняет задачу, используя LLM или генератор изображений.
6. Результат сохраняется в MongoDB.
7. В зависимости от типа задачи, создаются новые задачи и отправляются в Kafka.
8. Обновляется счетчик выполненных задач и прогресса генерации.

## 4. Типы задач и их описание

### 4.1. init_world_creation
- **Параметры**: промпт пользователя, количество пользователей, количество постов, уровень качества генерации
- **Действия**: проверяет валидность промпта, инициализирует запись WorldGenerationStatus
- **Создает задачи**: generate_world_description
- **Примечание**: создается в services/world-service/internal/service/world_service.go - createInitialGenerationTasks

### 4.2. generate_world_description
- **Параметры**: world_id, user_prompt
- **Действия**: генерирует с помощью LLM детальное описание мира (2-30 абзацев), включая технологии, культуру, особенности мира и существ, а так же много визуального описания мира. сохраняет WorldParameters  в mondo (чтобы не дублировать большое текстовое описание по всем задачам -все дальнейшие задачи сами скачивают это описание из mongo отдельным действием)
- **Результат**: структурированное описание мира, включая название
- **Создает задачи**: generate_world_image и generate_character_batch

### 4.3. generate_world_image
- **Параметры**: world_id, WorldParameters
- **Действия**: генерирует и сохраняет большое фоновое изображение для хэдера и иконку мира (промпт для изображения генерироуется с помощью LLM)
- **Результат**: URL-адреса загруженных изображений

### 4.4. generate_character_batch
- **Параметры**: world_id, WorldParameters, количество пользователей
- **Действия**: генерирует базовые описания (2-4 предложения) для всех пользователей мира в одном диалоге с LLM, алгоритмически распределяет количество постов для каждого пользователя (используется один диалог, чтобы все пользователи были в одном контексте LLM и не повторялись)
- **Результат**: массив базовых описаний пользователей с количеством постов
- **Создает задачи**: generate_character для каждого пользователя

### 4.5. generate_character
- **Параметры**: world_id, WorldParameters, character_base_description, posts_count
- **Действия**: генерирует детальное описание пользователя (внешность, характер, история), никнейм, текст в профиле, описание аватарки
- **Результат**: детальное описание пользователя и его профиля, 2-10 абзацев (так же генерирует много визуального описания - внешность пользователя, наполняет историю пользователя визуальной информацией чтобы ее потом было легче отобразить)
- **Создает задачи**: generate_character_avatar и generate_post_batch

### 4.6. generate_character_avatar
- **Параметры**: world_id, WorldParameters, character_id, avatar_description
- **Действия**: генерирует промпт, генерирует и загружает аватар пользователя в S3
- **Результат**: URL аватара

### 4.7. generate_post_batch
- **Параметры**: world_id, WorldParameters, character_id, character_description, posts_count
- **Действия**: генерирует краткие описания всех постов пользователя в одном диалоге с LLM (для сохранения контекста истории. Через эти посты должна раскрываться личность персонажа, и, возможно, его история жизни.)
- **Результат**: массив кратких описаний постов
- **Создает задачи**: generate_post для каждого поста

### 4.8. generate_post
- **Параметры**: world_id, WorldParameters, character_id, post_description, character_description
- **Действия**: генерирует детальный текст поста и детальный промпт для изображения
- **Результат**: текст поста и промпт для изображения
- **Создает задачи**: generate_post_image

### 4.9. generate_post_image
- **Параметры**: world_id, character_id, post_id, image_prompt
- **Действия**: генерирует изображение для поста и загружает его в S3
- **Результат**: URL изображения
- **Финальное действие**: создает пост через API других микросервисов

## 5. Взаимодействие с внешними системами

### 5.1. Работа с LLM (Google Gemini 2.5 Flash)
- Использовать structured output через JSON-схемы
- Запросы должны быть асинхронными
- Реализовать Circuit Breaker для обработки сбоев API
- Сохранять историю запросов и ответов для отладки в отдельном разделе mongo

### 5.2. Работа с генератором изображений
- Выбрать наиболее экономичное API (будет сделано позже, пока нужн осделать заглушку)
- Обеспечить асинхронные запросы
- Реализовать Circuit Breaker для обработки сбоев API
- Сохранять сгенерированные изображения в S3 через медиа-сервис

### 5.3. Взаимодействие с другими микросервисами
- Запросы для создания пользователей, постов, загрузки медиа
- Обрабатывать ошибки и повторять запросы при необходимости

## 6. Обработка ошибок и восстановление

### 6.1. Идемпотентная обработка задач
- Перед обработкой проверять статус задачи и наличие обрабатывающего воркера
- Использовать атомарные операции MongoDB для безопасного обновления статуса
- Регистрировать ID воркера при начале обработки задачи

### 6.2. Паттерн Circuit Breaker
- Реализовать для всех внешних API (LLM, генератор изображений, другие микросервисы)
- Настраиваемые пороги для перехода между состояниями CLOSED, OPEN, HALF-OPEN
- Экспоненциальная задержка между повторными попытками

### 6.3. Политика повторных попыток
- 4 попытки для критичных задач (относящихся к миру в целом)
- 2 попытки для некритичных задач (относящихся к отдельному пользователю/посту)
- Для неудачных попыток генерации постов из-за модерации контента:
  - Для первой неудачи: повторная попытка с модифицированным промптом
  - Для второй неудачи: создание поста-заглушки "deleted content"

## 7. Мониторинг прогресса генерации

### 7.1. Прогрессивная загрузка
- Обновлять запись WorldGenerationStatus после каждой завершенной задачи

### 7.2. Публикация событий (на будущее - пока что не реализуется, достаточно заглушек)
- Отправлять события о прогрессе в Kafka для обновления фронтенда
- Поддерживать "живую ленту" - события о создании новых постов

### 7.3. Управление лимитами
- Предварительно рассчитывать и устанавливать лимиты на API-вызовы (+25% запас)
- Инкрементно уменьшать счетчик перед каждым API-вызовом
- Отменять генерацию, если лимиты исчерпаны

## 8. Тестовый режим работы - в отдельном окружении

### 8.1. Изолированный Docker Compose
- Создать отдельный docker-compose.yml для тестового режима
- Включить только: сервис генерации, MongoDB, Kafka
- Автоматически отправлять начальное событие-промпт в Kafka при запуске

### 8.2. Расширенное логирование
- Логировать все этапы обработки задач с детализацией
- Выводить результаты генерации текста в консоль
- Сохранять сгенерированные изображения в отдельной директории на хосте

### 8.3. Интерфейс для тестирования
- Скрипт для запуска тестовой генерации с различными параметрами
- Возможность остановки и возобновления процесса генерации
- Инструменты для анализа результатов (просмотр логов, статистика, печать всех объектов в mongo по разделу или типу)

### 8.4. Тесты
- Отдельные тесты не нужны, я буду тестировать генерацию вручную

## 9. Технические требования и рекомендации

### 9.1. Структура проекта
```
ai-worker/
├── Dockerfile
├── docker-compose.yml
├── docker-compose.test.yml
├── requirements.txt
├── src/
│   ├── main.py
│   ├── config.py
│   ├── constants.py
│   ├── kafka/
│   │   ├── consumer.py
│   │   └── producer.py
│   ├── db/
│   │   ├── mongo.py
│   │   └── models.py
│   ├── api/
│   │   ├── llm.py
│   │   ├── image_generator.py
│   │   └── services.py
│   ├── core/
│   │   ├── base_job.py
│   │   ├── task.py
│   │   └── factory.py
│   ├── utils/
│   │   ├── circuit_breaker.py
│   │   ├── retries.py
│   │   └── progress.py
│   └── jobs/
│       ├── init_world_creation.py
│       ├── generate_world_description.py
│       ├── generate_world_image.py
│       ├── generate_character_batch.py
│       ├── generate_character.py
│       ├── generate_character_avatar.py
│       ├── generate_post_batch.py
│       ├── generate_post.py
│       └── generate_post_image.py
└── tests/
    ├── unit/
    └── integration/
```

### 9.2. Производительность и масштабируемость
- Использовать асинхронный код на основе `asyncio` для эффективной обработки I/O-bound задач.
- Поддерживать горизонтальное масштабирование через запуск нескольких инстансов

### 9.3. Мониторинг и логирование
- Подробное логирование с уровнями (DEBUG, INFO, WARNING, ERROR)
- Трассировка запросов через все микросервисы
- Метрики производительности (время обработки задач, очереди, API-вызовы)

### 9.4. Лимиты
нужно ограничить количество запросов и одновременно работающих воркеров:
```python
# Главный семафор для общего количества задач
task_semaphore = asyncio.Semaphore(100)  # 100 параллельных задач

# Семафоры для внешних API
llm_semaphore = asyncio.Semaphore(15)    # 15 параллельных запросов к LLM
image_semaphore = asyncio.Semaphore(10)  # 10 параллельных запросов к генератору изображений
```

## 10. Дополнительные требования

- Все Job-классы должны храниться в отдельных файлах для поддержания чистоты кода
- Сервис не должен читать данные напрямую из баз данных других микросервисов
- Документировать все публичные методы и классы
- Обновить README.md после завершения разработки


## 11. Конфиги
- Для конфига должен использоваться файл ./.env
- API ключи хранятся в переменных окружения хоста
