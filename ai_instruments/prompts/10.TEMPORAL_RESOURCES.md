# Результаты поиска по запросу 

```prompt
Я пишу пул воркеров на temporal workflow engine на Python.
Задача следующая: нужно генерировать фантастические виртуальные миры по типу instagram, и эта задача разбита на этапы (workflow).
например, есть этап описания мира, создания персонажей, и этап создания одного поста для персонажа. Каждая задача хранит какие-то данные в mongo (параметры задачи и генерации).
Используются запросы к LLM API, другим сервисам по grpc и базам данным.
Такой вопрос: как в temporal работать с общими ресурсами воркеров? задач много, они маленькие - и для каждой задачи нужно получить данные из mongo и сохранить их обратно. То есть нельзя просто создавать новое соединение для каждой задачи. И для потока тоже - так как в задаче много работы с медленными API, и одна задача может выполняться по минуте - и соединение будет висеть не использованное (техническое требование - поддержка высокой нагрузки: система генерации должна поддерживать горизонтальное масштабирование на тысячи и тысячи миров одновременно)

Как мне в моем проекте сделать работу с соединениями с базами данных?
```


# Ответ Perplexity

## Архитектура подключения к базам данных в распределенных системах

### Проблема состояния соединений в event-driven архитектуре

В системах, основанных на event-driven паттернах, таких как Temporal, каждый рабочий процесс (workflow) и активность (activity) должны проектироваться с учетом идемпотентности и изоляции состояния[^1][^6]. Однако соединения с внешними ресурсами, такими как MongoDB, по своей природе являются stateful-объектами, что создает фундаментальное противоречие.

Решение заключается в реализации **пулов соединений** с аппаратным ограничением максимального числа одновременных подключений[^2][^7]. Для Python особенно важно использовать асинхронные драйверы баз данных, такие как `motor` для MongoDB, которые интегрируются с event loop asyncio[^8].

### Шаблоны проектирования для управления соединениями

1. **Инициализация пула на уровне воркера**
Каждый экземпляр воркера при старте создает пул соединений фиксированного размера:
```python
from motor.motor_asyncio import AsyncIOMotorClient
from temporalio.worker import Worker

class MongoConnectionPool:
    def __init__(self, uri, max_size=10):
        self.pool = [AsyncIOMotorClient(uri) for _ in range(max_size)]
        self.semaphore = asyncio.Semaphore(max_size)

    async def get_connection(self):
        await self.semaphore.acquire()
        return self.pool.pop()

    async def release_connection(self, conn):
        self.pool.append(conn)
        self.semaphore.release()
```

2. **Инъекция зависимостей в активности**
Пул передается в активности через конструктор при регистрации воркера[^5][^7]:
```python
worker = Worker(
    client,
    task_queue="world-generation",
    activities=[create_activity(pool)],
    workflows=[WorldGenerationWorkflow]
)
```


## Оптимизация производительности при высокой нагрузке

### Настройка параметров Task Queue

Temporal предоставляет несколько ключевых параметров для управления параллелизмом[^2]:

- `max_concurrent_workflow_tasks`: максимальное число одновременных workflow-задач
- `max_concurrent_activities`: лимит параллельных activity-вызовов
- `max_task_queue_activities_per_second`: rate limiting для защиты БД

Эмпирическая формула для расчета оптимальных значений:

```
max_connections = (worker_count * max_concurrent_activities) / avg_activity_duration
```


### Использование асинхронного API MongoDB

Пример активности с асинхронным доступом к БД[^8]:

```python
@activity.defn(name="save_world_state")
async def save_world_state(ctx, world_data: dict):
    pool = ctx.activity.info.mongo_pool
    async with pool.get_connection() as client:
        db = client["worlds"]
        result = await db.worlds.update_one(
            {"world_id": world_data["id"]},
            {"$set": world_data},
            upsert=True
        )
        return result.upserted_id
```


## Обеспечение отказоустойчивости и согласованности данных

### Паттерн Circuit Breaker для соединений с БД

Реализация механизма автоматического переключения при сбоях:

```python
from temporalio import activity
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1))
async def safe_db_operation(query):
    try:
        return await execute_query(query)
    except MongoError as e:
        activity.heartbeat(f"DB error: {e}")
        raise
```


### Транзакционность в распределенных workflow

Использование Saga-паттерна для согласованности данных между микросервисами[^4]:

```python
@workflow.defn
class WorldGenerationSaga:
    @workflow.run
    async def run(self, params):
        try:
            await workflow.execute_activity(
                start_generation_phase,
                params,
                start_to_close_timeout=timedelta(minutes=5)
            )
            await workflow.execute_activity(
                validate_world_consistency,
                params,
                start_to_close_timeout=timedelta(minutes=2)
            )
        except Exception as e:
            await workflow.execute_activity(
                rollback_generation_steps,
                params,
                start_to_close_timeout=timedelta(minutes=5)
            )
            raise
```


## Мониторинг и диагностика проблем

### Метрики для анализа использования соединений

Temporal SDK предоставляет встроенные метрики Prometheus[^2]:

- `temporal_worker_task_slots_available`: доступные слоты для задач
- `temporal_activity_poll_success`: успешные операции с БД
- `temporal_activity_execution_failures`: ошибки выполнения

Настройка алертинга на ключевые метрики:

```python
alert: HighDatabaseLatency
expr: rate(temporal_activity_execution_latency_bucket{operation="mongo"}[5m]) > 0.1
for: 10m
```


## Горизонтальное масштабирование системы

### Стратегии шардирования данных

1. **Кластеризация MongoDB**
Использование sharded cluster с разделением по world_id:
```python
sh.shardCollection("worlds.worlds", {"world_id": "hashed"})
```

2. **Балансировка нагрузки между воркерами**
Динамическое регулирование количества воркеров на основе нагрузки:
```bash
kubectl autoscale deployment temporal-worker --cpu-percent=70 --min=3 --max=20
```


### Оптимизация шаблонов доступа к данным

- **Кеширование частозапрашиваемых данных** с использованием Redis
- **Пакетная обработка запросов** для снижения нагрузки на БД
- **Асинхронная репликация** для разделения нагрузки чтения/записи


## Заключение

Эффективное управление соединениями с базами данных в Temporal требует комплексного подхода, сочетающего правильную настройку пулов соединений, использование асинхронных паттернов программирования и глубокую интеграцию с возможностями самого движка. Реализация предложенных стратегий позволяет достичь линейного масштабирования системы до тысяч одновременных workflow-процессов при сохранении стабильности и отказоустойчивости.

Ключевые рекомендации:

1. Использовать пулы соединений на уровне воркеров
2. Настраивать rate limiting и приоритезацию задач
3. Внедрять Circuit Breaker и механизмы повтора
4. Мониторить ключевые метрики производительности
5. Применять горизонтальное шардирование данных

Дальнейшее развитие системы должно включать внедрение machine learning для предсказательной балансировки нагрузки и автоматической оптимизации параметров соединений на основе анализа исторических данных.

<div style="text-align: center">⁂</div>

[^1]: https://docs.temporal.io/develop/python

[^2]: https://docs.temporal.io/develop/worker-performance

[^3]: https://community.temporal.io/t/running-out-of-db-connections/4014

[^4]: https://www.linkedin.com/posts/temporal-technologies_building-invincible-applications-with-temporal-activity-7290760725369630721-Zxod

[^5]: https://temporal.io/blog/python-sdk-diving-into-workers-and-workflows

[^6]: https://docs.temporal.io/develop/python/temporal-clients

[^7]: https://community.temporal.io/t/sharing-resources-e-g-db-connection-for-activities-in-java/966

[^8]: http://athiemann.net/2023/01/16/temporal.html

[^9]: https://github.com/temporalio/sdk-python

[^10]: https://temporal.io/blog/resource-based-auto-tuning-for-workers

[^11]: https://docs.temporal.io/develop/python/core-application

[^12]: https://community.temporal.io/t/accessing-temporal-client-from-within-activity/12941

[^13]: https://community.temporal.io/t/passing-db-connection-objects-to-activities/5925

[^14]: https://learn.temporal.io/getting_started/python/

[^15]: https://docs.temporal.io/develop/python/python-sdk-sandbox

[^16]: https://community.temporal.io/t/unable-to-create-database-connections-from-workflow/16491

[^17]: https://python.temporal.io

[^18]: https://python.temporal.io/temporalio.worker._worker.html

[^19]: https://learn.temporal.io/getting_started/python/hello_world_in_python/

[^20]: https://stackoverflow.com/questions/76484558/how-to-write-a-temporal-worker-interceptor-class-in-temporal-python-sdk

[^21]: https://temporal.io/blog/python-sdk-your-first-application

[^22]: https://python.temporal.io/temporalio.client.Client.html

[^23]: https://python-oracledb.readthedocs.io/en/latest/user_guide/connection_handling.html

[^24]: https://github.com/rq/rq/issues/720

[^25]: https://support.safe.com/hc/en-us/articles/25407698305037-Sharing-Database-and-Web-Connections-in-FME-Form

[^26]: https://learn.temporal.io/tutorials/python/background-check/project-setup/

[^27]: https://community.temporal.io/t/invoking-coroutine-in-activity-python-sdk/1127

[^28]: https://python.temporal.io/temporalio.testing.ActivityEnvironment.html

[^29]: https://docs.temporal.io/develop/python/python-sdk-sync-vs-async

[^30]: https://python.temporal.io/temporalio.workflow.html

[^31]: https://onepointzero.app/workflows-in-python-using-temporal/

[^32]: https://pypi.org/project/temporalio/0.1a1/



# Ответ ChatGPT

In Temporal the *unit of reuse is the **Worker process***, so you create expensive objects **once at Worker start-up**, keep them in memory, and hand references to every Activity invocation running in that process.
Below is a step-by-step pattern that is proven to scale to “thousands and thousands of worlds” while keeping Mongo, gRPC, and HTTP connections hot and fully utilised.

---

## TL;DR

1. **Instantiate pooled clients (Motor/PyMongo, `grpc.aio.Channel`, `httpx.AsyncClient`, etc.) once per Worker** and pass them to Activity classes or functions.
2. **Never open external connections inside a Workflow**—only inside Activities; Workflows must stay deterministic.
3. **Tune both the Temporal Worker and each driver’s pool** (`maxConcurrentActivityExecutionSize`, `maxPoolSize`, `maxIdleTimeMS`, keep-alives, etc.) so they match.
4. **Scale out by process/pod**, not by opening more driver connections inside one process (PyMongo is *not* fork-safe, every process needs its own `MongoClient`).
5. **Close clients in a Worker shutdown hook** to avoid leaking file descriptors.

---

## 1  Worker vs. Activity life-cycle

* A Worker process can host many concurrent Activity executions; objects you create before `worker.run()` are therefore shared by all of them.
* Temporal maintainers recommend this pattern explicitly; you register Activities as class instances that already hold the resources you need. ([Temporal][1])
* The official Python SDK guide shows the same approach for an `aiohttp.ClientSession`; the same works for Mongo, gRPC, etc. ([Temporal Documentation][2])

### Minimal skeleton

```python
import asyncio, os, grpc, httpx
from temporalio.client import Client
from temporalio.worker import Worker, WorkerOptions
import motor.motor_asyncio as motor
from myapp.activities import WorldActivities
from myapp.workflows import GenerateWorldWorkflow
from myapp.llm_pb2_grpc import LLMStub

async def main() -> None:
    # ---- Temporal connection ------------------------------------------------
    tclient = await Client.connect("temporal:7233")

    # ---- Shared resources ----------------------------------------------------
    mongo = motor.AsyncIOMotorClient(
        os.environ["MONGO_URI"],
        maxPoolSize=200,          # tune with Worker concurrency
        minPoolSize=10,
        maxIdleTimeMS=30_000,
    )
    grpc_chan = grpc.aio.insecure_channel(
        os.environ["LLM_HOST"],
        options=[("grpc.keepalive_time_ms", 60_000)],
    )
    llm_stub = LLMStub(grpc_chan)
    http = httpx.AsyncClient(timeout=10)

    # Inject them into an Activity class
    activities = WorldActivities(mongo, llm_stub, http)

    # ---- Worker --------------------------------------------------------------
    worker_opts = WorkerOptions(
        max_concurrent_activity_task_executions=200,
        max_concurrent_workflow_task_executions=200,
    )                                   # see §3
    async with Worker(
        tclient,
        task_queue="worldgen",
        workflows=[GenerateWorldWorkflow],
        activities=[activities],
        worker_options=worker_opts,
    ):
        await asyncio.Event().wait()    # run forever

asyncio.run(main())
```

---

## 2  MongoDB client pooling details

| Driver                           | Why prefer it in Temporal Python                                                                                                       | Pool knobs you usually set                    |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------- |
| **Motor (`AsyncIOMotorClient`)** | Fully asyncio; sockets are reused by all concurrent Activities in the same event loop. ([motor.readthedocs.io][3])                     | `maxPoolSize`, `minPoolSize`, `maxIdleTimeMS` |
| **PyMongo (`MongoClient`)**      | OK for **synchronous** Activities; pools are thread-safe but *not fork-safe*, so create one per process. ([pymongo.readthedocs.io][4]) | Same three knobs                              |

`maxPoolSize` defaults to 100, so raise it until (pool wait ≃ 0) under expected parallelism. ([pymongo.readthedocs.io][5])

For long-idle workloads set `maxIdleTimeMS` (e.g. 30 s) so unused sockets are dropped before Kubernetes kills them.

---

## 3  Tuning Worker concurrency to match your pools

* `maxConcurrentActivityExecutionSize` (or the new **slot-supplier tuners**) caps how many Activities run in parallel inside one Worker. ([Temporal Documentation][6])
* Each parallel execution can grab a Mongo socket; therefore set
  `maxConcurrentActivityExecutionSize ≤ maxPoolSize`.
* If you run CPU-bound Activities in the same process, keep this number lower or split them into a dedicated task queue so that I/O and CPU don’t starve each other. ([Temporal][7])

> **Rule of thumb**: start with *Worker* 200 slots, *Mongo* 200 connections; scale them together and watch `worker_task_slots_available` / `worker_task_slots_used` metrics. ([Temporal Documentation][6])

---

## 4  gRPC / HTTP client reuse

gRPC recommends **one shared `Channel` per target** and to keep it alive with periodic keep-alives instead of opening a new TCP/TLS handshake each call. ([gRPC][8])
`httpx.AsyncClient` and `aiohttp.ClientSession` behave the same way for HTTP/REST or OpenAI-style APIs—create once, close on shutdown.

---

## 5  Shutting down cleanly

Add an `atexit` handler or wrap the Worker in `async with` and close:

```python
async with Worker(...):
    try:
        await asyncio.Event().wait()
    finally:
        mongo.close()
        await grpc_chan.close()
        await http.aclose()
```

---

## 6  Horizontal scaling & PODs

* Spin up **more Worker pods** (each with its own Mongo pool) instead of making one pod open thousands of sockets.
* Because `MongoClient` pools are *per process*, this naturally spreads load; just ensure MongoDB’s global connection limits are sized for the total number of pods.

---

## 7  Checklist before going to prod

| Item                                                                                   | Why                                                                |
| -------------------------------------------------------------------------------------- | ------------------------------------------------------------------ |
| Use **async Activities** (`motor`, `grpc.aio`, `httpx.AsyncClient`) for I/O-bound work | avoids blocking the event loop ([Temporal Documentation][2])       |
| Keep **Workflows pure** (no DB/API calls)                                              | determinism & replay safety                                        |
| Align **Worker slots ≈ driver pool size**                                              | prevents pool starvation                                           |
| Set **`maxIdleTimeMS`** and gRPC **keep-alives**                                       | leak-free long-running pods                                        |
| Emit **Temporal metrics** (`worker_task_slots_*`, `schedule_to_start_latency`)         | verify your configuration under load ([Temporal Documentation][6]) |
| Use **separate task queues** if some Activities are CPU-bound                          | better tuning and isolation ([Temporal][9])                        |

---

### Key references

1. Sharing resources across Activities in Temporal (community) ([Temporal][1])
2. Async Activity example injecting shared session (Python SDK docs) ([Temporal Documentation][2])
3. Worker performance & concurrency options (docs) ([Temporal Documentation][6])
4. Thread-safety and fork-safety of `MongoClient` (PyMongo FAQ) ([pymongo.readthedocs.io][4])
5. Default `maxPoolSize` = 100 (PyMongo FAQ) ([pymongo.readthedocs.io][5])
6. Motor async client API (docs) ([motor.readthedocs.io][3])
7. gRPC “always re-use stubs and channels” (perf guide) ([gRPC][8])
8. Thread-/pool-size discussion for Python workers (community) ([Temporal][7])
9. Worker concurrency sizing pitfalls (community) ([Temporal][10])
10. Limiting parallelism via task-queue isolation (community) ([Temporal][9])

Follow this blueprint and your Temporal-based world-generator will saturate thousands of concurrent universes without drowning in wasted sockets or cold DNS look-ups. Happy world-building!

[1]: https://community.temporal.io/t/sharing-resources-e-g-db-connection-for-activities-in-java/966?utm_source=chatgpt.com "Sharing Resources (e.g. DB connection) for Activities in Java"
[2]: https://docs.temporal.io/develop/python/python-sdk-sync-vs-async "Temporal Python SDK synchronous vs. asynchronous Activity implementations | Temporal Platform Documentation"
[3]: https://motor.readthedocs.io/en/1.2.5/api-asyncio/asyncio_motor_client.html "AsyncIOMotorClient – Connection to MongoDB — Motor 1.2.5 documentation"
[4]: https://pymongo.readthedocs.io/en/stable/faq.html "Frequently Asked Questions - PyMongo 4.13.0 documentation"
[5]: https://pymongo.readthedocs.io/en/stable/faq.html?utm_source=chatgpt.com "Frequently Asked Questions - PyMongo 4.13.0 documentation"
[6]: https://docs.temporal.io/develop/worker-performance "Worker performance | Temporal Platform Documentation"
[7]: https://community.temporal.io/t/trigger-workflow-with-concurrent-activities-using-threadpoolexecutor/10751?utm_source=chatgpt.com "Trigger workflow with concurrent activities using ThreadPoolExecutor"
[8]: https://grpc.io/docs/guides/performance/ "Performance Best Practices | gRPC"
[9]: https://community.temporal.io/t/clarification-combination-max-concurrent-activities-and-start-to-close-timeout/13274?utm_source=chatgpt.com "combination max_concurrent_activities and start_to_close_timeout ..."
[10]: https://community.temporal.io/t/confusion-regarding-max-concurrent-execution-size-for-activity-and-workflow/16597?utm_source=chatgpt.com "Confusion regarding max concurrent execution size for activity and ..."
