
У меня есть проект - (./README.md) - генерация виртуальных миров. сервис генерации - (services/ai-worker/README.md).

Я переделал механизм генерации с kafka на temporal workflow engine. Основа сделана, но сами заадчи воркеров сделаны в черновом виде.

Изучи проект, а затем перепроверь и допиши все jobs, чтобы они были как на старой версии.


Старые jobs: services/ai-worker/src/jobs/*.py
Новые jobs: services/ai-worker/src/workflows/*.py







Дело в том, что из LLM может вернуться не точно заданное количество персонажей или постов, а (иногда) - чуть больше или меньше. Перепроверь  логику перепроверки количества персонажей и количества их постов. (если персонажей       │
│   больше чем запращивали - нужно обрезать массив с ними. Если меньше - сгенерирвоать еще. Если колиество постов у персонажей не суммируется правильно - нужно убирать/добавлять по одному посту у случайного персонажа, пока            │
│   количество постов у всех персонажей в ответе в сумме не будет соответствовать запрашиваему) (generate_character_batch_workflow). Так же сделай аналогично для проверки количества постов - generate_post_batch_workflow




У меня есть проект - (./README.md) - генерация виртуальных миров. сервис генерации - (services/ai-worker/README.md).
Я переделал механизм генерации с kafka на temporal workflow engine. Основа сделана, но теперь я столкнулся с проблемой:
сейчас данные задачи передаются через temporal, но там есть ограничение на количество параметров в задаче - из-за этого некоторые задачи падают.
Поэтому я хочу сделать как было раньше (на kafka) - данные задачи должны храниться в mongo по id задачи. (id задачи - это отдельное uid, оно не связано с id в  temporal).
И между задачами передается не все данные, а только task_id
Новые jobs: services/ai-worker/src/workflows/*.py
старый код для работы с задачами в mongo - 
services/ai-worker/src/db/mongo.py:70-150
(нужно создать новые activity для создания и загрузки параметров задач, и передавать данные через эти activity)



Сразу перепиши все workflow на новый способ. Иди по workflow от начала (init_worl_creation) и до конца. Сделай так: все объекты-параметры задачи сделаем сериализуемыми-десериализуемыми из json. И добавим нвоый объект в
  BaseWorkflow - просто класс с task_id. И далее в существующий код добавим созранение и зугрзку этих объектов-данных задач (на основе значений из mongo). обновление задач не используй. . (может использовать Model для
  сериализации?). Подумай о решении, обсуди его со мной ultrathink


 1. task_id есть всегда (кроме InitWorldCreationWorkflow - тут параметры действительно передаются через парамтеры). 2. Напрмиер - в InitWorldCreationWorkflow мы формируем GenerateWorldDescriptionInput (этот код уже есть). Теперь
  нужно вызывать базовый метод, который сохранит задачу и вернет другой объект - который будет содержать только task_id (и этот объект и будет передаваться дальще). Далее в новой задаче (GenerateWorldDescription) будет вызываться
  еще один метод базового класса, который будет переводить этот объект в исходный GenerateWorldDescriptionInput. (Чтобы было удобно работать с объектом в формате json - нужно сдеать его BaseModel. чтобы было удобноработать с
  функцией в базовом классе - нужно в нее как параметр передавать сам класс, в который нужно загрузить данные - имею ввиду, конструктор класса (или как эта штука называется)
